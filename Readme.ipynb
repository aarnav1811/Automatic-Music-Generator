{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4dc454e7",
      "metadata": {
        "id": "4dc454e7"
      },
      "source": [
        "<h1 align = \"center\">PSC INNOVATIVE ASSIGNMENT</h1>\n",
        "<h2 align = \"center\">AUTOMATIC MUSIC GENERATION</h2>\n",
        "<h2 align = \"center\">21BCE002, 21BCE003, 21BCE020</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a4bbfc0",
      "metadata": {
        "id": "4a4bbfc0"
      },
      "source": [
        "<h3>LIBRARIES USED:</h3>\n",
        "\n",
        "1.) music21\n",
        "\n",
        "2.) glob\n",
        "\n",
        "3.) os\n",
        "\n",
        "4.) tqdm\n",
        "\n",
        "5.) numpy\n",
        "\n",
        "6.) random\n",
        "\n",
        "7.) tensorflow - for the main audio processing using LSTM.\n",
        "\n",
        "8.) keras(layers and models)\n",
        "\n",
        "9.) sklearn - the machine learning library for training and testing the model.\n",
        "\n",
        "\n",
        "CODE SNIPPET:\n",
        "--------------------------------------------------------------------------------------------------------------------------------\n",
        "<i>from music21 import *\n",
        "\n",
        "<i>import glob\n",
        "\n",
        "<i>from tqdm import tqdm\n",
        "\n",
        "<i>import numpy as np\n",
        "\n",
        "<i>import random\n",
        "\n",
        "<i>from tensorflow.keras.layers import LSTM,Dense,Input,Dropout\n",
        "\n",
        "<i>from tensorflow.keras.models import Sequential,Model,load_model\n",
        "\n",
        "<i>from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f87e5eac",
      "metadata": {
        "id": "f87e5eac"
      },
      "source": [
        "<h3>THE OBJECTIVE:</h3>\n",
        "\n",
        "- Our goal is to create our own original piece of music by using various audio files.\n",
        "- We achieved this by feeding a machine learning model some audio files in the form of 'midi' files.\n",
        "- The model would read and analyse those files and will train itself to produce music in a way it understands.\n",
        "- The 'end-product' of running this program will provide the user with a new 'midi' file which will be the program's own      composition of music"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7fa7a79b",
      "metadata": {
        "id": "7fa7a79b"
      },
      "source": [
        "<h3>HOW THE MODEL 'READS AND ANALYSES':</h3>\n",
        "\n",
        "- The machine learning model is fed various 'midi' files.\n",
        "- It 'learns' from those files what music should sound like.\n",
        "- By 'READING AND ANALYZING', we mean that the program takes all the midi files, separates all the files into various unique notes and chords the files are composed of.\n",
        "- The unique chords and notes are then used for testing and training the model, which helps it identify what sounds like 'good music'.\n",
        "\n",
        "<h4>USEFUL INFORMATION:</h4>\n",
        "\n",
        "- A 'chord' is made up of multiple notes. Thus, it makes sense for the model to split the chords encountered in the midi files into its respective 'unique' notes for work.\n",
        "\n",
        "\n",
        "CODE SNIPPET:\n",
        "--------------------------------------------------------------------------------------------------------------------------------------\n",
        "<i>def read_files(file):\n",
        "    \n",
        "<i> notes=[]\n",
        "\n",
        "<i> notes_to_parse=None\n",
        "\n",
        "<i> #parse the midi file\n",
        "\n",
        "<i> midi=converter.parse(file)\n",
        " \n",
        "<i> #seperate all instruments from the file\n",
        " \n",
        "<i> instrmt=instrument.partitionByInstrument(midi)\n",
        "\n",
        "<i>for part in instrmt.parts:\n",
        "\n",
        "<i> #fetch data only of Piano instrument\n",
        " \n",
        "<i> if 'Piano' in str(part):\n",
        " \n",
        "<i> notes_to_parse=part.recurse()\n",
        " \n",
        "\n",
        "<i> #iterate over all the parts of sub stream elements\n",
        " \n",
        "<i> #check if element's type is Note or chord\n",
        " \n",
        "<i> #if it is chord split them into notes\n",
        " \n",
        "<i> for element in notes_to_parse:\n",
        " \n",
        "<i> if type(element)==note.Note:\n",
        " \n",
        "<i>  notes.append(str(element.pitch))\n",
        "  \n",
        "<i> elif type(element)==chord.Chord:\n",
        " \n",
        "<i>  notes.append('.'.join(str(n) for n in element.normalOrder))\n",
        "\n",
        "<i>#return the list of notes\n",
        "\n",
        "<i>return notes\n",
        "\n",
        "<i>#retrieve paths recursively from inside the directories/files\n",
        "\n",
        "<i>file_path=[FILE_PATH]\n",
        "\n",
        "<i>all_files=glob.glob('All Midi Files/'+file_path[0]+'/*.mid',recursive=True)\n",
        "\n",
        "<i>#reading each midi file\n",
        "\n",
        "<i>notes_array = np.array([read_files(i) for i in tqdm(all_files,position=0,leave=True)])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1decbc50",
      "metadata": {
        "id": "1decbc50"
      },
      "source": [
        "<h3>BUILDING THE MODEL:</h3>\n",
        "\n",
        "- We used LSTM to build the model.\n",
        "- LSTM is a variety of RNNs(Recurrent Neural Networks), which is used by the model to learn long-term dependencies, especially in sequence prediction.\n",
        "\n",
        "<h4>HOW DOES SEQUENCE PREDICTION COME INTO PLAY HERE?</h4>\n",
        "\n",
        "- Sequence Prediction is used by the model to decide which note/chord is played after which note/chord, which is very important for generation of good music.\n",
        "\n",
        "\n",
        "CODE SNIPPET:\n",
        "--------------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "<i>#create the model\n",
        "\n",
        "<i>model = Sequential()\n",
        "\n",
        "<i>#create two stacked LSTM layer with the latent dimension of 256\n",
        "\n",
        "<i>model.add(LSTM(256,return_sequences=True,input_shape=(x_new.shape[1],x_new.shape[2])))\n",
        "\n",
        "<i>model.add(Dropout(0.2))\n",
        "\n",
        "<i>model.add(LSTM(256))\n",
        "\n",
        "<i>model.add(Dropout(0.2))\n",
        "\n",
        "<i>model.add(Dense(256,activation='relu'))\n",
        "\n",
        "<i>#fully connected layer for the output with softmax activation\n",
        "\n",
        "<i>model.add(Dense(len(note2ind),activation='softmax'))\n",
        "\n",
        "<i>model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0912de2d",
      "metadata": {
        "id": "0912de2d"
      },
      "source": [
        "<h3>TRAINING THE MODEL:</h3>\n",
        "\n",
        "- The model is now trained using the training set of notes.\n",
        "- We used 10 epochs to train the model.\n",
        "\n",
        "<b>*EPOCHS: Epochs are the number of times the training set of data is passed into the model to train.</b>\n",
        "\n",
        "SNAPSHOT OF THE CODE:\n",
        "--------------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "<i>#compile the model using Adam optimizer\n",
        "\n",
        "<i>model.compile(loss='sparse_categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "<i>#train the model on training sets and validate on testing sets\n",
        "\n",
        "<i>model.fit(\n",
        "\n",
        "<i> x_train, y_train,\n",
        " \n",
        "<i> batch_size = BatchSize,epochs = number_of_epochs,\n",
        " \n",
        "<i> validation_data = (x_test,y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bbf00593",
      "metadata": {
        "id": "bbf00593"
      },
      "source": [
        "<h3>SAMPLING PHASE:</h3>\n",
        "\n",
        "- This is the section where our efforts bear fruit. This is where the program is able to compose music.\n",
        "- The trained model is used to predict the position of the notes to produce good music.\n",
        "- The notes taken for training in a random order, and the predicted notes from the dataset will be stored in another list.\n",
        "\n",
        "CODE SNIPPET:\n",
        "--------------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "<i>#load the model\n",
        "\n",
        "<i>model = load_model(“s2s”)\n",
        "\n",
        "<i>#generate random index\n",
        "\n",
        "<i>index = np.random.randint(0,len(x_test)-1)\n",
        "\n",
        "<i>#get the data of generated index from x_test\n",
        "\n",
        "<i>music_pattern = x_test[index]\n",
        "\n",
        "<i>out_pred=[] #it will store predicted notes\n",
        "\n",
        "<i>#iterate till 200 note is generated\n",
        "\n",
        "<i>for i in range(200):\n",
        "\n",
        "<i> #reshape the music pattern\n",
        " \n",
        "<i> music_pattern = music_pattern.reshape(1,len(music_pattern),1)\n",
        "\n",
        "<i> #get the maximum probability value from the predicted output\n",
        " \n",
        "<i> pred_index = np.argmax(model.predict(music_pattern))\n",
        " \n",
        "<i> #get the note using predicted index and\n",
        " \n",
        "<i> #append to the output prediction list\n",
        " \n",
        "<i> out_pred.append(ind2note[pred_index])\n",
        " \n",
        "<i> music_pattern = np.append(music_pattern,pred_index)\n",
        "\n",
        "<i> #update the music pattern with one timestep ahead\n",
        " \n",
        "<i> music_pattern = music_pattern[1:]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6003ca38",
      "metadata": {
        "id": "6003ca38"
      },
      "source": [
        "<h3>SAVING THE FILE INTO A 'MIDI' FILE:</h3>\n",
        "\n",
        "- The output notes is then saved into a 'midi' file, which can then be converted to a playable format and played on a media player.\n",
        "\n",
        "CODE SNIPPET:\n",
        "--------------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "<i>output_notes = []\n",
        "\n",
        "<i>for offset,pattern in enumerate(out_pred):\n",
        "\n",
        "<i>#if pattern is a chord instance\n",
        "\n",
        "<i>if ('.' in pattern) or pattern.isdigit():\n",
        "\n",
        "<i> #split notes from the chord\n",
        " \n",
        "<i> notes_in_chord = pattern.split('.')\n",
        " \n",
        "<i> notes = []\n",
        " \n",
        "<i> for current_note in notes_in_chord:\n",
        " \n",
        "<i>  i_curr_note=int(current_note)\n",
        "  \n",
        "<i>  #cast the current note to Note object and\n",
        "  \n",
        "<i>  #append the current note\n",
        "  \n",
        "<i>  new_note = note.Note(i_curr_note)\n",
        "  \n",
        "<i>  new_note.storedInstrument = instrument.Piano()\n",
        "  \n",
        " <i> notes.append(new_note)\n",
        "\n",
        "<i> #cast the current note to Chord object\n",
        " \n",
        "<i> #offset will be 1 step ahead from the previous note\n",
        " \n",
        "<i> #as it will prevent notes to stack up\n",
        " \n",
        "<i> new_chord = chord.Chord(notes)\n",
        " \n",
        "<i> new_chord.offset = offset\n",
        " \n",
        "<i> output_notes.append(new_chord)\n",
        "\n",
        "<i>else:\n",
        "\n",
        " <i>#cast the pattern to Note object apply the offset and\n",
        " \n",
        " <i>#append the note\n",
        " \n",
        "<i> new_note = note.Note(pattern)\n",
        " \n",
        "<i> new_note.offset = offset\n",
        " \n",
        "<i> new_note.storedInstrument = instrument.Piano()\n",
        " \n",
        "<i> output_notes.append(new_note)\n",
        "\n",
        "<i>#save the midi file\n",
        "\n",
        "<i>midi_stream = stream.Stream(output_notes)\n",
        "\n",
        "<i>midi_stream.write('midi', fp='pred_music.mid')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}